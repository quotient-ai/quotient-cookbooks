{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Monitor a Web Research Agent with Exa, LangGraph & Quotient\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/quotient-ai/quotient-alpha/blob/main/cookbooks/agents/research/exa-quotient-agent.ipynb\">\n",
    " <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook shows how to build a LangGraph-based **research assistant** powered by [Exa](https://exa.ai) and Anthropic Claude. The agent answers real-world search queries using live web content via Exa's semantic search, and is monitored using [Quotient AI](https://www.quotientai.co/) to detect hallucinations, irrelevant retrievals, and other failure modes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use API keys from:\n",
    " - [Anthropic](https://www.anthropic.com/) â€” get your API key from the [Anthropic Console](https://console.anthropic.com/)\n",
    " - [Exa](https://exa.ai) â€” get your API key from the [Exa Dashboard](https://dashboard.exa.ai)\n",
    " - [Quotient AI](https://www.quotientai.co) â€” get your API key from the [Quotient AI app](https://app.quotientai.co)\n",
    " \n",
    "Both Exa and Quotient offer generous free tiers to get started; you can check out their pricing [here](https://exa.ai/pricing) and [here](https://www.quotientai.co/pricing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set API keys:\n",
    "os.environ['ANTHROPIC_API_KEY'] = \"anthropic-api-key\"\n",
    "os.environ['EXA_API_KEY'] = \"exa-api-key\"\n",
    "os.environ['QUOTIENT_API_KEY'] = \"quotient-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-anthropic langchain-exa langgraph quotientai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up a Research Agent with Exa + Anthropic\n",
    "\n",
    "In this step, we define a LangGraph agent that uses **ExaSearchRetriever** to gather live web content and Anthropic's Claude model for reasoning.\n",
    "\n",
    "What's happening here:\n",
    "\n",
    "- `ExaSearchRetriever` allows the agent to perform semantic web searches with highlights\n",
    "- `ChatAnthropic` initializes Claude as the core reasoning engine\n",
    "- We use LangGraph's `StateGraph` to create a workflow that:\n",
    "  - Takes user queries\n",
    "  - Searches the web with Exa\n",
    "  - Processes results with Claude\n",
    "  - Returns comprehensive answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "from langchain_exa import ExaSearchRetriever\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_web_content(query: str) -> List[str]:\n",
    "    \"\"\"Function to retrieve usable documents for AI assistant\"\"\"\n",
    "    # Initialize the Exa Search retriever\n",
    "    retriever = ExaSearchRetriever(k=3, highlights=True)\n",
    "\n",
    "    # Define how to extract relevant metadata from the search results\n",
    "    document_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    <source>\n",
    "        <url>{url}</url>\n",
    "        <highlights>{highlights}</highlights>\n",
    "    </source>\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create a chain to process the retrieved documents\n",
    "    document_chain = (\n",
    "        RunnableLambda(\n",
    "            lambda document: {\n",
    "                \"highlights\": document.metadata.get(\"highlights\", \"No highlights\"),\n",
    "                \"url\": document.metadata[\"url\"],\n",
    "            }\n",
    "        )\n",
    "        | document_prompt\n",
    "    )\n",
    "\n",
    "    # Execute the retrieval and processing chain\n",
    "    retrieval_chain = retriever | document_chain.map()\n",
    "\n",
    "    # Retrieve and return the documents\n",
    "    documents = retrieval_chain.invoke(query)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Determine whether to continue or end\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    return \"tools\" if last_message.tool_calls else END\n",
    "\n",
    "# Get current date for temporal context\n",
    "current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "# Create system prompt with current date\n",
    "system_prompt = SystemMessage(content=f\"\"\"You are a helpful assistant that answers questions based on provided context.\n",
    "                            Answer the following question using ONLY the provided context. If the context doesn't contain enough information to fully answer the question, acknowledge what information is missing.\n",
    "                            Today's date is {current_date}.\n",
    "                            \"\"\")\n",
    "    \n",
    "def create_agent():\n",
    "    \"\"\"Create a fresh instance of the agent\"\"\"\n",
    "\n",
    "    # Function to generate model responses\n",
    "    def call_model(state: MessagesState):\n",
    "        # Add system message if it's not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not any(isinstance(msg, SystemMessage) for msg in messages):\n",
    "            messages = [system_prompt] + messages\n",
    "        response = model.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # Define and bind the AI model\n",
    "    model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(\n",
    "        [retrieve_web_content]\n",
    "    )\n",
    "\n",
    "    # Define the workflow graph\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"agent\", call_model)\n",
    "    workflow.add_node(\"tools\", ToolNode([retrieve_web_content]))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # Compile the workflow into a runnable (without memory)\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Quotient SDK to Monitor the Agent\n",
    "\n",
    "In this step, we set up [Quotient AI](https://www.quotientai.co) to **monitor our LangGraph agent** as it answers real-world queries.\n",
    "\n",
    "Quotient allows us to:\n",
    "\n",
    "- Log each query and model response\n",
    "- Attach the retrieved documents for grounding checks\n",
    "- Automatically detect hallucinations (i.e., unsupported claims) and irrelevant documents\n",
    "\n",
    "The configuration below tells Quotient to log 100% of interactions and run hallucination detection on every one. This will give us full visibility into how our agent is performing, and whether it's staying grounded in the context it retrieves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<quotientai.client.QuotientLogger at 0x10bccb670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quotientai import QuotientAI\n",
    "\n",
    "# Initialize the Quotient SDK\n",
    "quotient = QuotientAI()\n",
    "\n",
    "quotient.logger.init(\n",
    "    # Name your application or project\n",
    "    app_name=\"exa-agent\",\n",
    "    # Set the environment (e.g., \"dev\", \"prod\", \"staging\")\n",
    "    environment=\"test\",\n",
    "    # Set the sample rate for logging (0-1)\n",
    "    sample_rate=1.0,\n",
    "    # Enable hallucination detection\n",
    "    hallucination_detection=True,\n",
    "    # Set the sample rate for detections (0-1)\n",
    "    hallucination_detection_sample_rate=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Queries Through the Agent and Log Responses to Quotient\n",
    "\n",
    "In this step, we simulate real user queries by reading from a `.jsonl` file and sending each query to the LangGraph agent. For each query, we:\n",
    "\n",
    "1. **Invoke the agent** using the LangGraph app, which triggers Claude + Exa tool calls\n",
    "2. **Capture the final model response** from the messages\n",
    "3. **Extract all documents** returned by Exa's semantic search\n",
    "4. **Format documents** into a structured list of `{\"page_content\": ..., \"metadata\": ...}` to support downstream evaluation\n",
    "5. **Log the full interaction to Quotient**, including:\n",
    "   - The original query\n",
    "   - The model's answer\n",
    "   - The retrieved documents for grounding checks\n",
    "   - Metadata such as model version for traceability\n",
    "\n",
    "Each interaction is logged with `quotient.log(...)`, enabling automatic hallucination detection and structured evaluation inside the Quotient platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Query: When did President Trump and Vice President Vance meet with Ukrainian President Volodymyr Zelenskyy in the Oval Office?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information retrieved, I can answer your question about when President Trump and Vice President Vance met with Ukrainian President Volodymyr Zelenskyy in the Oval Office.\n",
      "\n",
      "According to the White House website, President Trump hosted President Volodymyr Zelenskyy of Ukraine in the Oval Office on February 28, 2025. This information comes from a video title on the White House website: \"President Trump and Ukrainian President Zelenskyy in Oval Office, Feb. 28, 2025\".\n",
      "\n",
      "However, I must note that the retrieved information does not specifically mention Vice President Vance being present at this meeting. The sources only refer to President Trump and President Zelenskyy. If Vice President Vance was indeed part of this meeting, that information is not provided in the context I have.\n",
      "\n",
      "To summarize:\n",
      "- The meeting between President Trump and Ukrainian President Volodymyr Zelenskyy took place on February 28, 2025, in the Oval Office.\n",
      "- The presence of Vice President Vance at this meeting is not confirmed by the available information.\n",
      "\n",
      "If you need more specific information about Vice President Vance's involvement or any other details about the meeting, you may need to ask for additional searches or provide more context.\n",
      "ðŸ“ Logged to Quotient with log_id: 1291902c-2d25-4d49-8b2f-4e31294d723d\n",
      "\n",
      "ðŸ§  Query: When did The West Kirby Bookshop announce its expansion to new premises?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: I apologize, but after searching for information about The West Kirby Bookshop's expansion announcement, I couldn't find any relevant details in the provided context. The search results don't contain any information about a bookshop in West Kirby or its expansion plans.\n",
      "\n",
      "The context provided includes information about:\n",
      "1. A live music event in West Kirby on June 7, 2025\n",
      "2. An open studio tour for artists and makers in West Kirby, Hoylake, and Meols on June 14-15, 2025\n",
      "3. A brief mention of a swimming pool reopening\n",
      "\n",
      "Unfortunately, none of these articles mention The West Kirby Bookshop or any bookshop expansions. To answer your question accurately, we would need more specific information about the bookshop and its announcement. It's possible that the announcement was made at a different time or hasn't been covered in the sources available to me.\n",
      "\n",
      "If you have any additional information about when or where this announcement might have been made, or if you'd like me to search for more general information about bookshops in West Kirby, please let me know, and I'll be happy to help further.\n",
      "ðŸ“ Logged to Quotient with log_id: 20586c7f-0ab6-424b-97ca-7dc52da9b784\n",
      "\n",
      "ðŸ§  Query: Who postulated the 12 principles of Green Chemistry in the 1990s?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information retrieved, I can answer your question about who postulated the 12 principles of Green Chemistry in the 1990s.\n",
      "\n",
      "The 12 principles of Green Chemistry were postulated by Paul Anastas and John Warner in the 1990s. These two scientists co-authored several scientific papers and books, including the work that outlined the 12 Principles of Green Chemistry.\n",
      "\n",
      "Some key points:\n",
      "\n",
      "1. Paul Anastas and John Warner were childhood friends from Quincy, Massachusetts, who both became green chemists.\n",
      "\n",
      "2. They co-authored a book titled \"Green Chemistry: Theory and Practice,\" which included the 12 Principles of Green Chemistry.\n",
      "\n",
      "3. While the term \"green chemistry\" was coined in the early 1990s, their book helped define the motives and a common mission in this developing field.\n",
      "\n",
      "4. The 12 Principles of Green Chemistry have since served as the foundation for green chemistry curricula and as a blueprint for chemical industry practices worldwide.\n",
      "\n",
      "5. After the release of their book, there was a steady increase in the number of papers and patents published that included the term \"green chemistry.\"\n",
      "\n",
      "It's worth noting that both Anastas and Warner have had significant careers in the field of green chemistry. Paul Anastas, for instance, has worked with the EPA and is known as a \"Green Chemistry Guru.\" John Warner has been giving lectures on the importance and legacy of green chemistry in recent years.\n",
      "ðŸ“ Logged to Quotient with log_id: ba54a296-5a11-434b-9daf-d8cab4f6a55f\n",
      "\n",
      "ðŸ§  Query: According to the 'State of Education for Crisis-Affected Children and Adolescents: Access and Learning Outcomes Global Estimates 2025 Update', how many crisis-affected children of school age are out of school worldwide?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: I apologize, but I couldn't find the specific \"State of Education for Crisis-Affected Children and Adolescents: Access and Learning Outcomes Global Estimates 2025 Update\" report you mentioned. However, I did find some relevant information from a recent report by Education Cannot Wait, which provides statistics on crisis-affected children and education. While this may not be the exact 2025 update you're looking for, it offers the most recent data available to me. \n",
      "\n",
      "According to the information from Education Cannot Wait:\n",
      "\n",
      "Approximately 14.5 million crisis-affected children with functional difficulties are not attending school. Of these, about 76% (around 11 million) are concentrated in high-intensity crises.\n",
      "\n",
      "Additionally, the report mentions that:\n",
      "\n",
      "1. Access to secondary education in crisis-affected areas is inadequate, with approximately one-third of children in the lower secondary school age group being out of school.\n",
      "\n",
      "2. Nearly half of the children in the upper secondary school age group who are affected by crises are unable to access education.\n",
      "\n",
      "3. At least 25 million crisis-affected children aged 3 to the end of the expected completion of upper secondary education are estimated to be left out of interagency plans and appeals (9.4% of the global total).\n",
      "\n",
      "While this information doesn't provide a single, comprehensive figure for all crisis-affected children out of school worldwide, it does give us an idea of the scale of the problem. The numbers suggest that tens of millions of crisis-affected children are out of school, with at least 25 million being left out of interagency plans and appeals alone.\n",
      "\n",
      "It's important to note that this data is not from the specific 2025 update you mentioned, and the actual numbers might have changed by 2025. To get the most accurate and up-to-date information for 2025, you would need to refer to the specific report you mentioned, which doesn't seem to be available in my current search results.\n",
      "ðŸ“ Logged to Quotient with log_id: e18c520a-aef2-4495-aa0c-e55f5b7b46a6\n",
      "\n",
      "ðŸ§  Query: What was Apple's quarterly revenue for the fiscal 2025 second quarter?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information retrieved, I can answer your question about Apple's quarterly revenue for the fiscal 2025 second quarter.\n",
      "\n",
      "Apple's quarterly revenue for the fiscal 2025 second quarter was $95.4 billion. This information is consistently reported across multiple sources:\n",
      "\n",
      "1. According to Apple's official financial results announcement, as reported on last10k.com and BusinessWire, \"Apple today announced financial results for its fiscal 2025 second quarter ended March 29, 2025. The Company posted quarterly revenue of $95.4 billion, up 5 percent year over year.\"\n",
      "\n",
      "2. This figure is also confirmed by a report on iphonejd.com, which states, \"This year, the quarterly revenue was $95.4 billion, which was 5% better than this time last year and was Apple's second-best Q2 ever.\"\n",
      "\n",
      "Some additional context:\n",
      "- This represents a 5% increase compared to the same quarter in the previous year.\n",
      "- While it's a strong performance, it's not Apple's best Q2 ever. The record for Q2 was set three years ago (which would be 2022) at $97.3 billion.\n",
      "- This quarter ran from December 29, 2024, to March 29, 2025.\n",
      "- Apple's CEO, Tim Cook, highlighted strong performance in Services and the introduction of new products like the iPhone 16e and new Macs and iPads during this period.\n",
      "ðŸ“ Logged to Quotient with log_id: f8e33aaf-a738-4357-baac-8671699478e3\n",
      "\n",
      "ðŸ§  Query: When are the final election results for the May 20th, 2025 Special District Election scheduled to be certified?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: I apologize, but after searching for information about the May 20th, 2025 Special District Election in Oregon, I couldn't find a specific date for when the final election results are scheduled to be certified. The information I found mostly pertains to the election itself, but not the certification of results.\n",
      "\n",
      "Here's what I did find:\n",
      "\n",
      "1. The election is indeed scheduled for May 20, 2025.\n",
      "2. Ballots are set to be mailed to voters on May 1, 2025.\n",
      "3. For those running for a position within a district, the deadline to file an SEL 190 form with the Marion County Clerk's Office is March 20, 2025.\n",
      "\n",
      "However, the certification date for the final election results is not mentioned in the available information. Typically, election results are certified within a few weeks after the election, but the exact date can vary depending on state and local laws and procedures.\n",
      "\n",
      "To get the specific certification date for the final election results, you might need to:\n",
      "\n",
      "1. Check the Oregon Secretary of State's website for more detailed election information.\n",
      "2. Contact your local county elections office directly.\n",
      "3. Look for updates closer to the election date, as this information might be released nearer to May 2025.\n",
      "\n",
      "I apologize that I couldn't provide the exact certification date you're looking for. If you need this specific information, I recommend contacting Oregon's election officials directly for the most accurate and up-to-date information.\n",
      "ðŸ“ Logged to Quotient with log_id: 70b9a990-263a-4745-8471-2bf1b6acf0d2\n",
      "\n",
      "ðŸ§  Query: When is the final of the FIFA Club World Cup 2025 scheduled to take place?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: I apologize, but after searching for information about the FIFA Club World Cup 2025, I couldn't find a specific date for the final match. The search results provided some general information about the tournament but did not include the exact date of the final.\n",
      "\n",
      "Here's what I can tell you based on the information retrieved:\n",
      "\n",
      "1. The FIFA Club World Cup 2025 is indeed scheduled to take place.\n",
      "2. DAZN, a sports entertainment platform, has been announced as the exclusive global broadcaster for the tournament.\n",
      "3. The final is set to be held at MetLife Stadium, which is also the site of the 2026 World Cup final.\n",
      "\n",
      "However, the exact date of the final is not mentioned in the retrieved information. It's possible that as of June 20, 2025 (our current date), the specific schedule for the tournament might not have been officially announced or widely publicized yet.\n",
      "\n",
      "To get the exact date of the final, you might need to:\n",
      "1. Check FIFA's official website or social media channels for the most up-to-date information.\n",
      "2. Look for announcements from DAZN, as they are the official broadcasters.\n",
      "3. Keep an eye on sports news outlets as the tournament date approaches, as they're likely to report on the schedule once it's released.\n",
      "\n",
      "I apologize that I couldn't provide the specific date you're looking for. If you need more precise information, you may want to check these sources directly or ask again closer to the expected tournament date when more details might be available.\n",
      "ðŸ“ Logged to Quotient with log_id: b9319790-359b-4003-922f-00b8bbd4a291\n",
      "\n",
      "ðŸ§  Query: What initiative introduced reusable digital workflows for archaeology in 2025?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information retrieved, I couldn't find a specific initiative that introduced reusable digital workflows for archaeology in 2025. However, I can provide some relevant information about recent developments in digital archaeology that are close to what you're asking about:\n",
      "\n",
      "1. AutArch: While not specifically mentioned as a 2025 initiative, AutArch is described as a scalable system that can serve the growing field of digital humanities in archaeology. It's designed to be applicable to any material and can grow with increasing demands. This represents an important step forward in applying artificial intelligence to archaeological research.\n",
      "\n",
      "2. Storytelling in Archaeological Data Production: There's a mention of a research project focusing on challenging \"archaeonormativity\" through storytelling. While this isn't explicitly about reusable digital workflows, it does represent an innovative approach to archaeological data production and interpretation.\n",
      "\n",
      "3. Innovation in Archaeological Methods and Practice: A source discusses the heterogeneity of global archaeological methodology and the need for innovation in methods and practice. It mentions the potential of new initiatives to affect archaeological interpretation and create different conditions for practitioners and communities to experience archaeology more richly, safely, and justly.\n",
      "\n",
      "These developments suggest that there is ongoing work in the field of digital archaeology to create more efficient, scalable, and innovative methods for data collection and interpretation. However, I couldn't find information about a specific initiative in 2025 that introduced reusable digital workflows for archaeology.\n",
      "\n",
      "If you're looking for a particular initiative or have more specific information about what you're seeking, please let me know, and I can try to search for more targeted information.\n",
      "ðŸ“ Logged to Quotient with log_id: 3b5cf361-9d25-4ca6-af79-801006812b86\n",
      "\n",
      "ðŸ§  Query: Who was named acting administrator of the Federal Emergency Management Agency on Thursday, May 8, 2025?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information retrieved, I can answer your question about who was named acting administrator of the Federal Emergency Management Agency (FEMA) on Thursday, May 8, 2025.\n",
      "\n",
      "David Richardson was named acting administrator of FEMA on Thursday, May 8, 2025. \n",
      "\n",
      "Here are the key details:\n",
      "\n",
      "1. David Richardson is a former Marine Corps officer who served in Afghanistan, Iraq, and Africa.\n",
      "2. Prior to this appointment, he was serving as the Department of Homeland Security's assistant secretary for countering weapons of mass destruction.\n",
      "3. It's noted that he does not appear to have any experience in managing natural disasters.\n",
      "\n",
      "The article also mentions that Richardson's appointment came after the previous administrator, Cameron Hamilton, was ousted. During Hamilton's last appearance before a House Appropriations subcommittee on Wednesday (presumably May 7, 2025), he had shared concerns about how FEMA assistance is administered.\n",
      "\n",
      "It's worth noting that this appointment is for an acting role, which typically means it's a temporary position until a permanent administrator is nominated and confirmed.\n",
      "ðŸ“ Logged to Quotient with log_id: 210531b4-8871-472b-b9e7-e2521209ffe7\n",
      "\n",
      "ðŸ§  Query: What is the monthly cost of the Apple Music Family Plan as of 2025?\n",
      "\n",
      "ðŸ¤– Running query through agent...\n",
      "\n",
      "âž¡ï¸ Final answer: Based on the information I've retrieved, I can answer your question about the monthly cost of the Apple Music Family Plan as of 2025.\n",
      "\n",
      "According to the source from musconv.com, as of 2025, the Apple Music Family Plan costs $16.99 per month.\n",
      "\n",
      "Here's a breakdown of the pricing information provided:\n",
      "1. Individual Plan: $10.99 per month\n",
      "2. Family Plan: $16.99 per month\n",
      "3. Student Plan: $5.99 per month\n",
      "\n",
      "It's worth noting that this information comes from a third-party website, and while it appears to be current for 2025, it's always a good idea to verify such information directly with Apple for the most accurate and up-to-date pricing.\n",
      "\n",
      "The other sources I retrieved don't provide specific pricing information for 2025, but they do confirm the existence of the Family Plan and mention that it allows multiple users to access Apple Music under one subscription.\n",
      "\n",
      "To use the Family Plan, you need to set up Family Sharing, and then everyone in your family group will automatically have access to Apple Music once you've subscribed to the Family Plan.\n",
      "ðŸ“ Logged to Quotient with log_id: 9fc57878-db58-414e-a6ef-ac5da154a3e8\n",
      "\n",
      "âœ… Successfully logged 10 queries to Quotient\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import ast\n",
    "from typing import List\n",
    "\n",
    "def parse_string_prompt_value(text: str) -> List[dict]:\n",
    "    \"\"\"Parse StringPromptValue responses into documents\"\"\"\n",
    "    # First, find all StringPromptValue instances in the content\n",
    "    pattern = r'StringPromptValue\\(text=\"(.*?)\"\\)'  # Simplified pattern\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    documents = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            # Extract URL and highlights from the XML-like structure\n",
    "            url_match = re.search(r'<url>(.*?)</url>', match)\n",
    "            highlights_match = re.search(r'<highlights>\\[(.*?)\\]</highlights>', match)\n",
    "            \n",
    "            url = url_match.group(1) if url_match else \"No URL\"\n",
    "            highlights_str = highlights_match.group(1) if highlights_match else \"\"\n",
    "            \n",
    "            # Clean up the highlights string and convert to list\n",
    "            highlights = [h.strip().strip(\"'\") for h in highlights_str.split(\"|\") if h.strip()]\n",
    "            \n",
    "            # Format document for Quotient\n",
    "            doc = {\n",
    "                \"page_content\": match,  # The full content\n",
    "                \"metadata\": {\n",
    "                    \"url\": url,\n",
    "                    \"highlights\": highlights\n",
    "                }\n",
    "            }\n",
    "            documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error parsing StringPromptValue: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Load queries from file\n",
    "with open(\"search_queries.jsonl\") as f:\n",
    "    all_queries = [json.loads(line)[\"question\"] for line in f]\n",
    "\n",
    "log_ids = []\n",
    "num_queries = 10\n",
    "\n",
    "# Randomly select queries\n",
    "queries = random.sample(all_queries, min(num_queries, len(all_queries)))\n",
    "\n",
    "# Run each query through the agent\n",
    "for i, query in enumerate(queries[:num_queries]):\n",
    "    print(f\"\\nðŸ§  Query: {query}\")\n",
    "    \n",
    "    # Run the query through the LangGraph app\n",
    "    print(\"\\nðŸ¤– Running query through agent...\")\n",
    "\n",
    "    app = create_agent()\n",
    "    \n",
    "    final_state = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        config={\"configurable\": {\"thread_id\": i}},\n",
    "    )\n",
    "    \n",
    "    # Get the final response\n",
    "    final_response = final_state[\"messages\"][-1].content\n",
    "    print(f\"\\nâž¡ï¸ Final answer: {final_response}\")\n",
    "\n",
    "    # Collect all documents from tool results\n",
    "    formatted_docs = []\n",
    "\n",
    "    messages = final_state[\"messages\"]\n",
    "    \n",
    "    for j, msg in enumerate(messages):\n",
    "        if isinstance(msg.content, str) and \"StringPromptValue\" in msg.content:\n",
    "            # Direct StringPromptValue in message content\n",
    "            docs = parse_string_prompt_value(msg.content)\n",
    "            formatted_docs.extend(docs)\n",
    "\n",
    "    # Log to Quotient\n",
    "    if formatted_docs:\n",
    "        try:\n",
    "            log_id = quotient.log(\n",
    "                user_query=query,\n",
    "                model_output=final_response,\n",
    "                documents=formatted_docs,\n",
    "                tags={\n",
    "                    'model': \"claude-3-7-sonnet-20250219\",\n",
    "                    'thread_id': i\n",
    "                }\n",
    "            )\n",
    "            print(f\"ðŸ“ Logged to Quotient with log_id: {log_id}\")\n",
    "            log_ids.append(log_id)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error logging to Quotient: {str(e)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No documents were collected to log\")\n",
    "\n",
    "print(f\"\\nâœ… Successfully logged {len(log_ids)} queries to Quotient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review detections in Quotient\n",
    "\n",
    "You can now view your logs and detections in the [Quotient dashboard](app.quotientai.co), where you can also filter them by tags and environments to identify common failure patterns.\n",
    "\n",
    "![Quotient AI Dashboard](Agent_Monitoring.png \"Quotient AI Dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You've Built\n",
    "\n",
    "You've built a fully functional, monitoring-included research agent that:\n",
    "\n",
    "- Handles real-time web queries using Exa + OpenAI\n",
    "- Retrieves and extracts live documents with state-of-the-art search capabilities\n",
    "- Automatically logs each response with Quotient for monitoring\n",
    "- Flags hallucinations, irrelevant context, or broken reasoning\n",
    "- Leverages Exa's Python SDK for seamless integration\n",
    "\n",
    "This setup can scale from notebook experiments to production pipelines, letting you benchmark different models, debug search performance, and monitor AI agents for critical issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### How to interpret the results\n",
    "> - Well-grounded systems typically show **< 5% hallucination rate**. If yours is higher, itâ€™s often a signal that either your data ingestion, retrieval pipeline, or prompting needs improvement.\n",
    "> - High-performing systems typically show **> 75% document relevance**. Lower scores may signal ambiguous user queries, incorrect retrieval, or noisy source data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Grab the detection results from Quotient\n",
    "\n",
    "Quotient's detections are now available to fetch via the Quotient SDK using the `log_id` you received earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:43<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 10\n",
      "Percentage of hallucinations: 90.00%\n",
      "Average percentage of relevant documents: 28.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "hallucination_detections = []\n",
    "doc_relevancy_detections = []\n",
    "\n",
    "for id in tqdm(log_ids):\n",
    "    try:\n",
    "        detection = quotient.poll_for_detection(log_id=id)\n",
    "        # Add the hallucination detection to the hallucination_detections list\n",
    "        hallucination_detections.append(detection.has_hallucination)\n",
    "        # Add the document relevancy detection to the doc_relevancy_detections list\n",
    "        docs = detection.log_documents\n",
    "        doc_relevancy_detections.append(sum(1 for doc in docs if doc.get('is_relevant') is True) / len(docs) if docs else None)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Number of results: {len(log_ids)}\")\n",
    "print(f\"Percentage of hallucinations: {sum(hallucination_detections)/len(hallucination_detections)*100:.2f}%\")\n",
    "print(f\"Average percentage of relevant documents: {sum(doc_relevancy_detections)/len(doc_relevancy_detections)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tavily-quotient-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
