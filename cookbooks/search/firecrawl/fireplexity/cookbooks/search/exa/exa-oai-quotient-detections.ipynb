{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Build a RAG Pipeline with Exa Search & OpenAI\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/quotient-ai/quotient-cookbooks/blob/main/cookbooks/search/exa/exa-oai-quotient-detections.ipynb\">\n",
        " <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "This cookbook demonstrates how to build a Retrieval Augmented Generation (RAG) pipeline using [Exa](https://exa.ai/) for AI web search, [OpenAI](https://openai.com) for generating answers from the retrieved content, and [Quotient AI](https://www.quotientai.co/) for monitoring search quality and detecting hallucinations in answers.\n",
        "\n",
        "We'll cover:\n",
        "- Setting up Exa for AI web search\n",
        "- Using OpenAI to generate answers from search results\n",
        "- Logging search results and answers in Quotient\n",
        "- Automatically detecting hallucinations and irrelevant results\n",
        "- Understanding common failure cases and how to fix them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "! pip install -qU quotientai exa-py openai tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 0: Grab your API keys\n",
        "\n",
        "We'll use API keys from:\n",
        " - [OpenAI](www.openai.com) ‚Äî get your API key from the [OpenAI API platform](https://platform.openai.com/login)\n",
        " - [Exa](https://exa.ai/) ‚Äî get your API key from the [Exa dashboard](https://dashboard.exa.ai/)\n",
        " - [Quotient AI](https://www.quotientai.co) ‚Äî get your API key from the [Quotient AI app](https://app.quotientai.co)\n",
        " \n",
        "Both Exa and Quotient offer generous free tiers to get started; you can check out their pricing [here](https://exa.ai/pricing) and [here](https://www.quotientai.co/pricing).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# Set API keys:\n",
        "os.environ['EXA_API_KEY'] = \"exa_api_key_here\"\n",
        "os.environ['QUOTIENT_API_KEY'] =\"quotient_api_key_here\"\n",
        "os.environ['OPENAI_API_KEY'] =\"quotient_api_key_here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Set up Exa, OpenAI and Quotient clients\n",
        "\n",
        "We'll use:\n",
        "- Exa's `search_and_contents` API to retrieve relevant web content\n",
        "- OpenAI `gpt-4o` to generate answers based on the retrieved content\n",
        "- Quotient to monitor the quality of our search and generation pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from exa_py import Exa\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize Exa client\n",
        "exa = Exa(os.getenv(\"EXA_API_KEY\"))\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quotient is an intelligent observability platform designed for retrieval-augmented and search-augmented AI systems.\n",
        "\n",
        "Quotient performs automated detections on two key fronts each time you send it a log:\n",
        "\n",
        "- **Hallucination:** Identifies statements in the model output that are unsupported by the retrieved documents or that contradict them. This flagging is done at the sentence level and returns a boolean indicator if any part of the answer contains a hallucination.\n",
        "\n",
        "- **Document Relevance:** Evaluates each retrieved document to determine whether it meaningfully contributed to grounding the answer. Quotient returns relevance labels for all documents, helping gauge retrieval and search quality.\n",
        "  \n",
        "These capabilities are enabled automatically when `hallucination_detection=True` is set during logger initialization.\n",
        "\n",
        "Below, we'll set up the Quotient logger, send each AI-search result for automatic evaluation, and retrieve structured logs and detections:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<quotientai.client.QuotientLogger at 0x1205f79d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from quotientai import QuotientAI, DetectionType\n",
        "\n",
        "# Initialize Quotient SDK\n",
        "quotient = QuotientAI()\n",
        "\n",
        "logger = quotient.logger.init(\n",
        "    # Name your application or project\n",
        "    app_name=\"exa-search-eval\",\n",
        "    # Set the environment (e.g., \"dev\", \"prod\", \"staging\")\n",
        "    environment=\"test\",\n",
        "    # Set the sample rate for logging (0-1.0)\n",
        "    sample_rate=1.0,\n",
        "    # this will automatically run hallucination detection on 100% of your model outputs in relation to the documents you provide\n",
        "    detections=[DetectionType.HALLUCINATION, DetectionType.DOCUMENT_RELEVANCY],\n",
        "    detection_sample_rate=1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Get a set of example queries\n",
        "\n",
        "We'll evaluate on a set of realistic user queries covering a diverse set of topics. From each sample, we will use the `question` attribute to run a fresh search and compare the generated answer against retrieved documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load queries from file\n",
        "with open(\"search_queries.jsonl\") as f:\n",
        "    queries = [json.loads(line)[\"question\"] for line in f]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can connect Quotient to a live development or production environment and run detections automatically as data comes in ‚Äî no manual setup required beyond the few-lines-of-code initial integration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Run the RAG pipeline\n",
        "\n",
        "Let's process our queries using:\n",
        "1. Exa for searching and retrieving relevant content\n",
        "2. OpenAI for generating answers from the retrieved content\n",
        "3. Quotient for monitoring the quality of results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† What is the top emerging technology in 2025 according to the article '25 New Technology Trends for 2025'?\n",
            "‚û°Ô∏è The top emerging technology in 2025 according to the article \"25 New Technology Trends for 2025\" is Generative AI.\n",
            "üìù Logged to Quotient with log_id: 3c9c3df5-96c2-424d-b04d-aa038548681d\n",
            "\n",
            "üß† What is the name of the 105-qubit quantum processor unveiled by Alphabet?\n",
            "‚û°Ô∏è The name of the 105-qubit quantum processor unveiled by Alphabet is \"Willow.\"\n",
            "üìù Logged to Quotient with log_id: b5ba8323-3499-44d7-9577-edad62650a9a\n",
            "\n",
            "üß† What is the projected market size of the global 5G market by 2026 according to the article 'Top 25 New Technology Trends in 2025' on GeeksforGeeks?\n",
            "‚û°Ô∏è The context provided does not specify the projected market size of the global 5G market by 2026 according to the article 'Top 25 New Technology Trends in 2025' on GeeksforGeeks. Additional information from the article would be needed to answer this question.\n",
            "üìù Logged to Quotient with log_id: cdffd0f9-fac4-496c-8997-677cbf08f0c0\n",
            "\n",
            "üß† According to the 2025 AI Index from Stanford University‚Äôs Institute for Human-Centered Artificial Intelligence, how many notable AI models came from the United States in 2024?\n",
            "‚û°Ô∏è According to the 2025 AI Index from Stanford University‚Äôs Institute for Human-Centered Artificial Intelligence, 40 notable AI models came from the United States in 2024.\n",
            "üìù Logged to Quotient with log_id: f0091a72-82d9-4d70-a91b-c6c925f7313a\n",
            "\n",
            "üß† What is the title of the article discussing the impact of AI on business, industry, and everyday life by 2025?\n",
            "‚û°Ô∏è The title of the article discussing the impact of AI on business, industry, and everyday life by 2025 is not explicitly provided in the context.\n",
            "üìù Logged to Quotient with log_id: 1c4d4ebd-c0d9-4482-a84c-e2ec9bd25502\n",
            "\n",
            "üß† When did the Morgan Stanley Technology, Media & Telecom Conference take place in 2025?\n",
            "‚û°Ô∏è The Morgan Stanley Technology, Media & Telecom Conference took place from March 3-6, 2025, in San Francisco.\n",
            "üìù Logged to Quotient with log_id: cf8c53ee-56a9-40dc-b34f-0cbd40badd02\n",
            "\n",
            "üß† Who were awarded the Nobel Prize for chemistry in October 2024 for their work on AI-related protein folding tools?\n",
            "‚û°Ô∏è The Nobel Prize in Chemistry in October 2024 was awarded to David Baker, Demis Hassabis, and John M. Jumper for their work on AI-related protein folding tools. David Baker was recognized for computational protein design, while Demis Hassabis and John Jumper were recognized for protein structure prediction.\n",
            "üìù Logged to Quotient with log_id: 2a68eec9-3b4b-45b7-b811-5ba04be40049\n",
            "\n",
            "üß† What is the expected clean energy technology spending in 2025 according to the 'Top Cleantech Trends for 2025' report by S&P Global?\n",
            "‚û°Ô∏è The expected clean energy technology spending in 2025, according to the 'Top Cleantech Trends for 2025' report by S&P Global, is projected to reach $670 billion.\n",
            "üìù Logged to Quotient with log_id: a9effde6-5fb9-4a3d-a19f-d461f1d6f252\n",
            "\n",
            "üß† According to the article '4 key trends to watch in clean energy technology in 2025', by how much did the cost of lithium-ion batteries fall in 2024?\n",
            "‚û°Ô∏è According to the article, the cost of lithium-ion batteries fell by 20% in 2024.\n",
            "üìù Logged to Quotient with log_id: 2b09faf3-25ab-4971-bfb3-792f5478c3b8\n",
            "\n",
            "üß† According to the 2025 Renewable Energy Industry Outlook by Deloitte, what was the percentage increase in utility-scale solar capacity additions in the United States between January and August 2023 compared to the same period in 2022?\n",
            "‚û°Ô∏è The provided context does not contain specific information about the percentage increase in utility-scale solar capacity additions in the United States between January and August 2023 compared to the same period in 2022. Additional information from the 2025 Renewable Energy Industry Outlook by Deloitte would be needed to answer this question.\n",
            "üìù Logged to Quotient with log_id: e2dac04e-882b-41a9-a115-1c457ee83bce\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "log_ids = []\n",
        "\n",
        "num_queries = 10\n",
        "\n",
        "for query in queries[:num_queries]:\n",
        "    print(f\"\\nüß† {query}\")\n",
        "    \n",
        "    # Search with Exa\n",
        "    search_response = exa.search_and_contents(\n",
        "        query,\n",
        "        text=True\n",
        "    )\n",
        "    \n",
        "    # Extract relevant content from search results\n",
        "    contexts = [result.text for result in search_response.results]\n",
        "    \n",
        "    # Format prompt for OpenAI\n",
        "    prompt = f\"\"\"Answer the following question using ONLY the provided context. If the context doesn't contain enough information to fully answer the question, acknowledge what information is missing.\n",
        "\n",
        "Context:\n",
        "{contexts}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Generate answer with OpenAI\n",
        "    completion = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "    \n",
        "    answer = completion.choices[0].message.content\n",
        "    print(f\"‚û°Ô∏è {answer}\")\n",
        "    \n",
        "    # Log to Quotient\n",
        "    log_id = quotient.log(\n",
        "        user_query=query,\n",
        "        model_output=answer,\n",
        "        documents=[str(doc) for doc in search_response.results],\n",
        "    )\n",
        "    print(f\"üìù Logged to Quotient with log_id: {log_id}\")\n",
        "    \n",
        "    results.append({\"query\": query, \"answer\": answer})\n",
        "    log_ids.append(log_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can connect Quotient to a live development or production environment and run detections automatically as data comes in ‚Äî no manual setup required beyond the few-lines-of-code initial integration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How It Works\n",
        "\n",
        "When `.log()` is called:\n",
        "\n",
        "1. **Data ingestion:** The query, model output, and all retrieved document contents are logged to Quotient.\n",
        "\n",
        "2. **Async detection pipeline:** Quotient runs:\n",
        "- **Hallucination detection**, labeling the output as hallucinated or not.\n",
        "- **Document relevance scoring**, marking which retrieved documents helped ground the output \n",
        "\n",
        "3. **Result retrieval:** You can poll or fetch detections linked to your `log_id`.\n",
        "\n",
        "4. **Monitor and troubleshoot in the Quotient app:** Access the [Quotient dashboard](app.quotientai.co) to:\n",
        "- Monitor you AI system over time\n",
        "- Review flagged hallucinated sentences.\n",
        "- See which documents were irrelevant.\n",
        "- Compare across tags or environments for deeper insights.\n",
        "\n",
        "For full implementation details, visit the Quotient [docs](https://docs.quotientai.co/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Review detections in Quotient\n",
        "\n",
        "You can now view your logs and detections in the [Quotient dashboard](app.quotientai.co), where you can also filter them by tags and environments to identify common failure patterns.\n",
        "\n",
        "![Quotient AI Dashboard](Quotient_Dashboard.png \"Quotient AI Dashboard\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## What You‚Äôve Built\n",
        "\n",
        "A lightweight search and monitoring pipeline that:\n",
        "- Runs live AI search queries\n",
        "- Automatically checks if answers are grounded in retrieved evidence\n",
        "- Flags hallucinations and irrelevant retrievals\n",
        "\n",
        "You can scale this to monitor production traffic, benchmark retrieval and search performance, or compare different models side by side."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to interpret the results\n",
        "- Well-grounded systems typically show **< 5% hallucination rate**. If yours is higher, it‚Äôs often a signal that either your data ingestion, retrieval pipeline, or prompting needs improvement.\n",
        "\n",
        "- High-performing systems typically show **> 75% document relevance**. Lower scores may signal ambiguous user queries, incorrect retrieval, or noisy source data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# (Optional) Grab the detection results from Quotient\n",
        "\n",
        "Quotient's detections are now available to fetch via the Quotient SDK using the `log_id` you received earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of results: 10\n",
            "Percentage of hallucinations: 10.00%\n",
            "Average percentage of relevant documents: 69.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "hallucination_detections = []\n",
        "doc_relevancy_detections = []\n",
        "\n",
        "for id in tqdm(log_ids):\n",
        "    try:\n",
        "        detection = quotient.poll_for_detection(log_id=id)\n",
        "        # Add the hallucination detection to the hallucination_detections list\n",
        "        hallucination_detections.append(detection.has_hallucination)\n",
        "        # Add the document relevancy detection to the doc_relevancy_detections list\n",
        "        docs = detection.log_documents\n",
        "        doc_relevancy_detections.append(sum(1 for doc in docs if doc.get('is_relevant') is True) / len(docs) if docs else None)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Number of results: {len(log_ids)}\")\n",
        "print(f\"Percentage of hallucinations: {sum(hallucination_detections)/len(hallucination_detections)*100:.2f}%\")\n",
        "print(f\"Average percentage of relevant documents: {sum(doc_relevancy_detections)/len(doc_relevancy_detections)*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tavily-quotient-eval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
